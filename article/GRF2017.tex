\documentclass[a4paper,12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{times}
\usepackage[compact]{titlesec}
\usepackage[numbers,sort&compress]{natbib}
\usepackage{amsmath}
\linespread{1.0}

\begin{document}

%\title{Personalized Oncology Supported by Next-Generation Computer-Aided Drug Repositioning, Ensemble Docking and Deep Learning}
\title{A Next-­Generation Computer­-Aided Drug Discovery Platform for Anticancer Drug Repurposing Supported by Large-­Scale Cheminformatics Databases and Interdisciplinary Laboratory Validations}
\maketitle

\section*{Primary Field}

E2 2209 Bioinformatics

\section*{Secondary Field}

M2 1204 Cancer

\section*{Keywords}

Personalized medicine, anticancer therapy, drug repurposing, molecular docking, virtual screening, deep learning, interaction profiling

\section*{Abstract}

Developing a new drug could cost as much as US\$2.6B over 13.5 years. Both the industry and academia are intensively demanding robust computational methods to facilitate or even automate the process of modern drug discovery. This is termed computer-aided drug discovery (CADD).

CADD tools are sometimes used as a metaphor for medicinal chemists' bread and butter, reflecting their importance in R\&D. Unfortunately, many CADD tools are commercial, proprietary, not portable, or difficult to use. This reality has inevitably imposed a huge obstacle for R\&D productivity. Therefore in the past six years, we have been contributing to creating a free, open source, next-generation CADD toolset, aiming to substantially simplify the use of such tools while taking advantages of the latest methodological advancements.

To this end, our first attempt was the development of a heterogeneous platform named istar, which encapsulated high-throughput virtual screening, machine-learning binding affinity estimation, molecular interaction profiling and visualization into an automatic and unified pipeline, freely available at http://istar.cse.cuhk.edu.hk. Since it was launched in October 2013, istar has served 24583 web sessions to 11507 users from 2201 cities in 114 countries. These promising statistics demonstrate the utility of our previous work.

Our toolset was validated not only retrospectively on community benchmarks, but also prospectively in interdisciplinary real-world problems. Collaborating with an external team of clinical physicians, we have recently rediscovered seven drugs as anticancer agents, as they were shown to exhibit submicromolar inhibitory effects to colorectal, hepatocellular, and bladder carcinomas in vitro in assays and in vivo in mice. These newly identified medications of marketed drugs vigorously present an alternative and cheap clinical therapy for the treatment of cancers, hopefully saving the precious lives of millions of patients who cannot afford expensive imported drugs. We have filed patent applications for four of these novel medications.

Building upon our initial but successful work, in this project we propose to continue to enhance our in-house CADD platform in these key aspects: drug repositioning, ensemble docking, interaction profiling and molecular visualization. Briefly speaking, drug repositioning guarantees a fast and cheap route to new medications with a low attrition rate, as most preclinical optimizations and toxicity assessments are probably satisfied; ensemble docking would generate reliable binding poses as it takes into accounts structural variability of multiple protein conformations, and it also allows to focus on a patient-specific mutant subtype of the disease on a personalized basis; interaction profiling and molecular visualization permit to inspect and reveal the underlying binding mechanism through which the drug becomes effective, and also shed light on the cause of drug resistence at a fine-grained molecular level. We carefully choose these state-of-the-art technologies to study and improve because we firmly believe that they will, when properly integrated, constitute a powerful and unprecedented approach to modern drug discovery success.

Since the proposed approach is for general purposes, its medical applications are not limited to combating cancers, but could be expanded to treat other common diseases such as hyperuricemia, which we are already working on, provided that the structure of the protein of therapeutic interest is available, which is the only requirement of using our proposed platform. Fortunately, such macromolecular structural data are rapidly growing year by year. For popular proteins, their structures are usually experimentally solved. For rare proteins, their structures can be computationally modeled. In either case, the only prerequisite for user input is likely to be circumvented, thus we feel confident that the proposed system will be of wide use.

\section*{Long-term Impact}

This proposal is designed to significantly increase drug discovery success rate in a pragmatic and practical manner. Our proposed next-generation CADD platform will be able to reveal the fundamental mechanism that governs molecular binding, and suggest ways to strengthen or weaken such binding. With this essential knowledge, a considerably higher success rate can be anticipated when it comes to constructing novel compounds from molecular fragments, optimizing chemical scaffolds, improving target selectivity, minimizing off-target side effects, finding new indications of approved drugs, or even predicting synergistic outcome of drug combinations. Two notable long-term impacts will be that 1) more alternative and affordable drug therapies will become available for a broad range of patients who will otherwise have to opt for expensive treatments, and 2) personalized medicine will be realized which assists in making medical decisions, practices, interventions and products tailored to the individual patient based on their response or risk of disease by considering their mutant subtype of pharmacophoric proteins.

\section*{Project Objectives}

\begin{enumerate}
  \item To collect and curate compound data from multiple external sources, including approved, experimental and withdrawn drugs (not only in US, but also in Europe, UK, Canada, Japan), regulated chemicals, herbal isolates, traditional Chinese medicines, natural products, and easily synthesizable compounds.\label{objective:cdata}
  \item To develop and release a new version of molecular docking software with atomic contact parameters and scoring function terms tuned to more consistently produce low-energy conformations geometrically closer to the co-crystallized conformation.\label{objective:idock}
%  \item To debug and revise the protein-ligand interaction profiling algorithm currently implemented in our molecular visualizer named iview, and verify the profiler using a database of known and putative interactions in the structural human proteome.
%  \item To rewrite, modulize, accelerate and standardize iview by exploiting the new features of JavaScript's latest specification codenamed ECMAScript 6, for instance, asynchronous programming.
  \item To create a new web server to seamlessly consolidate the above-mentioned data sources, docking methods, profiling algorithms and visualization features in order to streamline automatic ensemble docking of various types of compounds on a personalized basis.\label{objective:edock}
  \item To understand and elaborate molecular binding mechanism and analyze binding patterns at a fine-grained atomic level, and to suggest directions to strengthen or weaken intermolecular interactions so as to maximize selectivity and minimize side effect.\label{objective:iview}
  \item To utilize edock in identifying novel inhibitors of selected oncoproteins of patient-specific subtypes to achieve personalized oncology.\label{objective:edockapp}
  \item To evaluate the efficacy and cytotoxicity of candidate anticancer compounds in vitro and in vivo, and file patent applications for those showing significant inhibitory activities.\label{objective:wetval}
\end{enumerate}

\section*{Background of Research}

Computer-aided drug discovery (CADD) has now been widely accepted as a cost- and time-efficient strategy alternative to purely biochemical approaches. Robust and reliable computational methods are highly demanded by the pharmaceutical industry in order to accelerate or automate the early phases of modern drug discovery prior to preclinical experiments.

Although improvements to CADD tools are constantly reported, from a practical and pragmatic standpoint we unfortunately observe that many of them are commercial and proprietary. Freeware is normally designed to tackle a specific challenge in a specific domain only. These software programs developed by seaprate groups often follow diverse standards, requiring different input formats and generating different output formats, which would lead to complicated and error-prone chaining operations if the task were to combine multiple tools in different areas of CADD to achieve one single complete objective. This is often the case in virtual screening, a classical and daunting problem in CADD.

Virtual screening refers to searching libraries of compounds to identify those which are likely bioactive against a selected drug target. Virtual screening can be methodologically categoried into ligand-based virtual screening (LBVS) and docking-based virtual screening (DBVS), with the difference being that DBVS requires a 3D structure of the target but LBVS does not. In this project we concentrate on DBVS only, though we are meanwhile intensively researching LBVS approaches \citep{1749}. A typical workflow of DBVS includes molecular docking of a library of compounds against a target protein, followed by estimation of binding affinity, optionally interaction profiling and visualization, and then selection of candidate compounds. These individual steps will be outlined in the following two sections: works done by others and works done by us.

\subsection*{Works done by others}

Protein-ligand docking is a computational method that predicts how a small molecule, termed ligand, binds to a target protein, as well as how strongly they bind. Hence docking is useful in elaborating intermolecular interactions and enhancing the potency and selectivity of binding. In the context of DBVS, once a target protein is identified, a database of compounds will be docked against the protein, and their binding strength will be evaluated too. This is to shortlist compounds that are likely to show the strongest binding towards proteins intended to be inhibited (maximizing efficacy), or compounds that are likely to show the weakest binding towards proteins intended not to be inhibited (minimizing side effect).

The AutoDock suite \citep{1730} is unquestionably the most cited free software for protein-ligand docking. In particular, AutoDock Vina \citep{595} is a competitive docking program not only because it is free and open source, but also because it has been shown to substantially improve the average accuracy of binding mode prediction and run faster by an order of magnitude than its counterpart AutoDock 4 \citep{596}. Since Vina was released in the second half of 2010, it has been cited more than 3,700 times in just six years! The great success of Vina has led to a plenty of subsequent tools derived from Vina but improved in certain aspects. To name some, QuickVina \citep{1193} and QuickVina 2 \citep{1664} introduced first-order-consistency-check heuristics to accelerate local conformational search; VinaMPI \citep{1329} exploited Message Passing Interface (MPI) to distribute computing tasks to cluster computers for parallel execution; \citeauthor{1716} \citep{1716} invented a new, improved hybrid scoring function through combining the energy terms from AutoDock and Vina; Vinardo \citep{1741} proposed a scheme to systematically tune the scoring function parameters and suggested new values for the weights of each term; PSOVina \citep{1789} implemented particle swarm optimization algorithm and reduced the execution time by 51-60\% without compromising the prediction accuracy.

Although docking has managed to produce reasonably good binding poses with a success rate of more than 50\% \citep{1362}, it has been reviewed \citep{1695} that the traditionally low accuracy of the scoring function is a critical limitating factor of precisely estimating the affinity upon binding. To address this limitation, numerous scoring functions have been proposed. Linear scoring functions (e.g. Cyscore \citep{1372} and WScore \citep{1736}) are defined by the assumption of a fixed functional form to relate the predicted binding affinity to the numerical features that characterize the protein-ligand complex. They often employ standard multivariate linear regression (MLR) on experimental data to calibrate the coefficients in a weighted sum of physically meaningful terms as an estimation of binding affinity. Recent years have seen a fast growing number of new developments of machine-learning scoring functions, with RF-Score \citep{564} being the first that introduced a large improvement over classical approaches. RF-Score employed random forest and its second version RF-Score-v2 \citep{1370} increased predictive performance by substituting more precise distance-dependent features. CScore \citep{1194}, B2Bscore \citep{1410} and SFCscoreRF \citep{1347} are other examples which are also based on random forest. Apart from random forest, other machine-learning algorithms have been applied too. SVR-KB and SVR-EP \citep{963}, ID-Score \citep{1305} and MD-SVR \citep{1452} are representative scoring functions based on support vector regression, whereas NNScore 2.0 \citep{977} is based on neural networks.

As a downstream procedure of docking, visualization plays an important role in elucidating intermolecular interactions at an atomic level and aiding candidate compound selection. Thanks to the popularity of web servers and services, a number of online molecular visualizers have arisen in the past few years. Compared with offline counterparts, web-based visualizers have the apparent advantage of allowing users to conveniently visualize and inspect 3D structures directly in a modern browser, saving the trivial effort of downloading and installing any prerequisite. JSmol \citep{1314} is a JavaScript rewrite of the tradional and defacto visualizer Jmol (http://www.jmol.org). GLmol (http://webglmol.sourceforge.jp), 3Dmol.js \citep{1652} and NGL Viewer \citep{1666} are prevalent WebGL molecular viewers exploiting hardware rendering.

Described above are solitary pieces of standalone tools which were designed to solve a specific problem of CADD. There are some attempts on the feasibility of full automation of protein-ligand docking, analysis and visualization. DOCK Blaster \citep{557} utilizes DOCK \citep{1222} as the docking engine and ZINC \citep{1178} as the compound database. iScreen \citep{899} utilizes PLANTS \citep{607,779} as the docking engine and TCM@Taiwan \citep{528} as the compound database.

\subsubsection*{Works done by us}

In the past six years, we have been constructing a next-generation CADD toolset, which features several key modules: 1) a molecular docking program for high-throughput DBVS \citep{1153}, 2) a software-as-a-service platform for general-purpose web applications \citep{1362}, 3) an interactive web visualizer tailored to DBVS \citep{1366,1265}, 4) two accurate scoring functions for predicting intermolecular binding affinity of crystal and docked poses \citep{1647,1796,1433,1795,1797,1434}, 5) a de novo drug design tool considering synthetic feasibility \citep{1409,1387}, and 6) a shape recognition web server for ultrahigh-throughput LBVS \citep{1749}. It is worthwhile to highlight that all our tools are free and open source, well maintained and recognized.

In 2012 we developed a protein-ligand docking program called idock \citep{1153}. The goal was to further improve the computational performance so as to screen larger databases of compounds within a reasonable time. To this end, we substantially revised the numerical approximation algorithm of atomic free energy calculation from linear interpolation to table loookup, and introduced a heuristic of disabling inactive torsions to reduce the dimension of variables in conformational optimization. Unlike Vina where the input protein structure has to be parsed and energy grid maps have to be populated every time it attempts to dock a single ligand, in idock these are just one-off tasks and the results will be cached and reused. Compared with Vina, idock obtained a speedup of 3.3x in terms of CPU time and a speedup of 7.5x in terms of elapsed time on average, making it particularly suitable for performing large-scale DBVS.

In 2013 we implemented a modern software-as-a-service platform called istar \citep{1362}, originally motivated by the desire to realize molecular data preparation, format conversion, DBVS, analysis and visualization in one go, considerably relaxing the requirements on user's knowledge and expertise. Unlike DOCK Blaster or iScreen which neither support selecting compounds to dock with physiochemical properties nor allowing monitoring job progress in real time, our istar supports both features and additionally enables post-docking analysis such as interaction profiling and visualization, permitting users to easily study and investigate the binding mode of candidate compounds. As a byproduct, a huge database of more than 23 million purchasable compounds covering a large space of chemical diversity was provided for screening. This is thus far the largest open source web server ever available for performing DBVS. To date, istar has served 24583 web sessions to 11507 users from 2201 cities in 114 countries worldwide, according to Google Analytics.

In 2014 we developed an interactive molecular visualizer called iview \citep{1366,1265} embracing the WebGL technology, thus exploiting hardware rendering and implementing easy accessibility and platform independence. The unique feature that distinguishes iview from all other visualizers is its inherent support for docking entity extraction, binding cavity identification and binding pose analysis, tailor-made for virtual screening, both DBVS and LBVS. In terms of DBVS functionalities, iview enables macromolecular surface generation ported from the EDTSurf algorithm \citep{1297} and binding interaction profiling ported from the BINANA algorithm \citep{1413}.

In addition to tool development, we have meanwhile conducted empirical research on the feasibility of using machine-learning algorithms to enhance scoring function precision. First, we investigated under what circumstances machine-learning scoring functions would outperform classical ones, and found that this is the case when there are sufficient numerical features and training samples \citep{1432}. Based on this finding, we improved RF-Score by incorporating six additional features derived from Vina and by expanding the training set to all available structures in the refined set of PDBbind \citep{1633}. This led to the release of RF-Score-v3 \citep{1647}, a new tool for accurately predicting the binding affinity of a crystal pose.

Next, we studied the impact of docking pose generation error on the accuracy of machine-learning scoring functions \citep{1795,1797,1434}, and proposed a procedure to correct a substantial part of this error which consists of calibrating the scoring functions with re-docked poses, rather than co-crystallised poses. As a result, test set performance after this error-correcting procedure was much closer to that of predicting the binding affinity in the absence of pose generation error. This led to the release of RF-Score-v4 \citep{1795}, a new tool offering accurate estimation of binding affinity of a docked pose.

Furthermore, we demonstrated for the first time that training with low-quality structural and interaction data can still improve predictive performance \citep{1663}, contrary to the widely-held belief that additional performance can only be gained from high-quality data. This novel finding gives a new direction to further increase predictive accuracy.

Most importantly, our toolset has been independently validated to be practically useful in tackling real-world challenges. Collaborating with a team of clinical physicians led by the Co-I, we prospectively applied our toolset and successfully repurposed seven approved or experimental drugs that exhibited submicromolar inhibitory effect to colorectal, hepatocellular or bladder carcinomas \textit{in vitro} and \textit{in vivo} in nude mice \citep{1667,1681}. The newly identified medications of marketed drugs, which have a history of safe human use, vigorously present an alternative but cheap clinical therapy for cancers, hopefully saving millions of lives as many patients cannot afford costly imported drugs. In another case study, jointly with a medicinal chemist, we adopted the same computational approach and managed to reposition another approved drug as an anticancer agent \textit{in vitro}. In the third case study, collaborating with another clinical physician, we expanded our toolset's applicability domain and targetted the disease of gout (aka hyperuricemia), and discovered another approved drug which effectively reduced the serum uric acid levels in hyperuricemic mice \textit{in vivo}. Taken together, these independently-conducted case studies have sufficiently proved the success and significance of our work. We have filed patent applications for four of the new drug indications and will soon submit one more.

\section*{Research Plan and Methodology}

Sitting in the central position of this proposal is our promise to create a next-generation CADD platform in order to provide a complete solution to DBVS instead of simply supplying isolated pieces of solitary tools for each individual task. Here we define the adjective next-generation to be widely applicable and methodolocally advanced. One big contribution and commitment is that we guarantee our software will be free and open source under a permissive license.

The following subsections describe our plan to collect and cleanse compound data, realize ensemble docking on a personalized basis, and prospectively applying the platform to interdisciplinary anticancer drug discovery.

\subsection*{Collection and curation of compound data from multiple sources}

Compound data collection is the very first step. There are a lot of external sources of compound data. Manipulating a wide spectrum of data could be challenging, so we set up selection criteria to ensure effectiveness. To achieve project objective \ref{objective:cdata}, we decide to choose databases that are a) free and publicly available, b) popular and reliable, and c) of potential use in diverse scenarios. Therefore, we will focus on the following data sources: DrugBank \citep{1594}, which contains approved, experimental and withdrawn drugs; TCM@Taiwan \citep{528}, which contains traditional Chinese medicines; SCUBIDOO \citep{1682}, which contains computationally created chemical compounds optimized toward high likelihood of synthetic tractability. There are important reasons of choosing these data. As a matter of fact, among the 84 drug products introduced to market in 2013, new indications of existing drugs accounted for 20\%. It is well known that medicinal plants and natural products generally cause fewer side effects than western drugs, which implies a higher success rate and a shorter time to marketing. Easily synthesizable compounds represent novel structures that are largely unexplored, enabling unpatented and diverse compounds to be discovered.
%Create a table to list these databases and number of compounds. Plot statistics and histogram distributions of physiochemcal properties.

After data collection, the next step would be data curation. Here a three-step curation procedure is proposed, consisting of deduplication, conformer generation, and format conversion. First, we will filter out compounds containing missing or incomplete information (e.g. without a SMILES string), and remove duplicate compounds by calculating and comparing their canonical SMILES representation. Next, we will use a recent protocol, namely ETKDG \citep{1697}, to generate low-energy 3D conformers for each compound. The ETKDG protocol is chosen because it includes experimental torsional-angle preferences and additional knowledge of flat aromatic rings and linear triple bonds into the original distance geometry algorithm, which, by combining a post-processing step, was found to offer the best results in accuracy and second best in terms of efficiency comparing to four other popular conformer generators \citep{1127}. Finally we will convert the generated conformers to appropriate file formats to feed to idock for DBVS, aggregate individual records to form a unified dataset, and create an index and an interface for database query. Precalculated physiochemical properties will be retained and organized as key-value pairs. Note that the above steps will not be performed manually, which would be tedious and error-prone. Instead, we will write computer scripts to automatically download and cleanse data. Unlike many other works where multiple data sources are to be integrated maually and the external data are collected only once, our use of computer scripts enables automatic data synchronization whenever the external sources are updated. This ensures our data will always be current.

The above-proposed compound data organization scheme is easy to manipulate and extend, making including future data sources as easy as just running the scripts. Depending on different applications, we will later consider supplementing the database with more types of compounds from ZINC15 \citep{1688}, WITHDRAWN \citep{1718}, SWEETLEAD \citep{1511}, TTD \citep{1790}, TCMSP \citep{1375}, SANCDB \citep{1680}, PubChem \citep{1701} and ChEMBL \citep{1424}, further inflating the significance of our work. This project is innovative in that different sources of compound data will be analyzed, which represents a new opportunity given the recent availability of compiled sets of such molecules. The collected databases can be meanwhile used in the context of LBVS \citep{1749}, though it is out of the scope of this proposal.

\subsection*{Calibration of scoring function parameters}

Vinardo \citep{1741} suggested an easy approach to fine tweaking the docking parameters. new version of idock incorporating revisions from Vinardo \citep{1741}.

\begin{equation}
\label{eqn:e}
e = \sum_{i < j} e_{ij}
\end{equation}
\begin{eqnarray}
\label{eqn:eij}
e_{ij} &=& (-0.035579) * Gauss_1(t_i, t_j, r_{ij}) \nonumber \\
       &+& (-0.005156) * Gauss_2(t_i, t_j, r_{ij}) \nonumber \\
       &+& (+0.840245) * Repulsion(t_i, t_j, r_{ij}) \nonumber \\
       &+& (-0.035069) * Hydrophobic(t_i, t_j, r_{ij}) \nonumber \\
       &+& (-0.587439) * HBonding(t_i, t_j, r_{ij})
\end{eqnarray}
\begin{equation}
\label{eqn:Gauss1}
Gauss_1(t_i, t_j, r_{ij}) = e^{-(d_{ij} / 0.5)^2}
\end{equation}
\begin{equation}
\label{eqn:Gauss2}
Gauss_2(t_i, t_j, r_{ij}) = e^{-((d_{ij} - 3) / 2)^2}
\end{equation}
\begin{equation}
\label{eqn:Repulsion}
Repulsion(t_i, t_j, r_{ij}) =
\begin{cases}
d_{ij}^2 & \text{if } d_{ij} < 0\\
0 &\text{if } d_{ij} \geq 0
\end{cases}
\end{equation}
\begin{equation}
\label{eqn:Hydrophobic}
Hydrophobic(t_i, t_j, r_{ij}) =
\begin{cases}
1 & \text{if } d_{ij} \leq 0.5\\
1.5 - d_{ij} & \text{if } 0.5 < d_{ij} < 1.5\\
0 & \text{if } d_{ij} \geq 1.5\\
\end{cases}
\end{equation}
\begin{equation}
\label{eqn:HBonding}
HBonding(t_i, t_j, r_{ij}) =\citep{1667,1681}
\begin{cases}
1 & \text{if } d_{ij} \leq -0.7\\
d_{ij} / (-0.7) & \text{if } -0.7 < d_{ij} < 0\\
0 & \text{if } d_{ij} \geq 0\\
\end{cases}
\end{equation}
\begin{equation}
\label{eqn:dij}
d_{ij} = r_{ij} - (R_{t_i} + R_{t_j})
\end{equation}

Rebuild RF-Score v4 \citep{1795} from docked poses generated by idock.

Deep neural network. Deep Learning in Drug Discovery \citep{1810}

It is worth mentioning that our department has recently installed gpu7 to gpu9 TITAN Z and 32 NVIDIA Tesla K20m GPU chips (79,872 CUDA cores in total). These programmable parallel processores provide extremely high computational throughput and tremendous memory bandwidth compared to conventional CPU chips. So future work: GPU acceleration.

%\subsection*{Interaction profiling and visualization}

%It helps to learn new binding patterns and preferences.

%interaction profiling: BINANA \citep{1413}, PLIP \citep{1665}, PDID \citep{1712}

%ES6 features, garbage collection, arrow methods, modules, asynchronous programming

\subsection*{Development of a brand new web server for automatic personalized medicine}

Purpose is to streamline protein chain extraction, search box auto definition, file format conversion.

In our hands, roughly half of the systems we have used for docking simulations will give useful results using the default rigid model for the receptor \citep{1730}. In other cases, protein motion will cause problems for the prediction of reasonable poses. 

For systems with larger motions of loops or domains, the relaxed complex method \citep{26} has shown success by sampling a variety of receptor conformations using molecular dynamics and then performing docking simulations on these snapshots.

Hence ensemble docking (Figure , to show multiple conformations). How to select structures? \citep{1704} Inexpensive Method for Selecting Receptor Structures for Virtual Screening. The discovery of adapalene and fluspirilene were our two previous successful cases of ensemble docking \citep{1667,1681}. Predicted protein structures of value for virtual ligand screening \citep{1322,1277}.

\subsection*{Prospective interdisciplinary applications in anticancer drug discovery}

Practically we will apply our tools and datasets to realizing personalized medicine, with the first attempt on personalized oncology.

Based on our previous successful experience in repurposing clinically approved drugs as anticancer agents, we will first collect as many structures of these oncogenic targets as possible from the PDB database \citep{537}. Good targets: CDK2/4/6, FGFR3, EGFR, PI3K, ALK, Bcr-Abl, XDH. Cyclin-dependent kinases (CDK) 2/4/6 have been widely acknowledged and thoroughly documented as key proteins regulating the cell cycle and hallmarks for cancers. Epidermal growth factor receptor (EGFR), fibroblast growth factor receptor (FGFR) 3, phosphoinositide 3-kinase (PI3K), and murine double minute 2 (MDM2) are other important therpeutic targets of cancers. For instances, CDK2/4/6: colorectal, hepatocellular cancers; FGFR3: bladder cancer; PI3K: lung cancer;

Use edock to automate the following steps: analyze the desired binding cavity with our iview \citep{1366}. We will then extract the protein entity, convert file formats, and invoke our idock \citep{1153} to perform ensemble docking, which has the advantage of guaranteeing a consistent binding strength on average over multiple structures of the same oncogenic target with structural variabilities. Next we will rank the compounds, visualize their predicted conformations using iview \citep{1366}, analyze their putative binding interactions. Incidentally, this whole computational pipeline can be automated via advanced scripting as soon as our next-generation CADD framework is developed.

survey their reported usages from literature, and shortlist candidates for wet verifications. Lastly we will conduct cell viability assays, cell apotosis assays, cell cycle assays, western blotting, clinical trials on animals, and finally on humans. We expect this project to be of great impact, as our findings could possibly save human lives in millions.

In the long run, beyond just cancers, we will utilize our toolset for computer-aided drug discovery in much wider areas, including but not limited to gout, hyperuricemia, influenza, herpes, HBV and HIV viruses.

\section*{Existing facilities and major equipment available for this research proposal}

Existing facilities and equipments are sufficient to complete the proposed project.

In the PI’s affiliation, which is CUHK’s department of computer science and engineering, there are high-performance computers.

In the Co-I’s affiliation, which is KMU’s biotechnology center, there are wet laboratories and devices, and cancer cell lines and animal models.

\section*{Release of Completion Report and Data Archive Possibilities and Public Access of Publications Resulting from Research Funded by the RGC}

We will release the brand new webserver named edock to the public upon project completion.

%We will release the following datasets to the public upon project completion:
%1) Curated collections of ~3000 approved drugs in US, Europe, Canada and Japan, with molecular properties and purchasing information.
%2) 23 million compounds in 3D format, ready for large-scale docking-based virtual screening.
%3) 1.7 billion conformers of 23 million compounds in 3D format, ready for large-scale shape-based virtual screening.

\section*{Education Plan}

A senior postdoctoral fellow will be hired to lead the project and to train two PhD students to conduct theoretical and systematic research in the field of computer-aided drug discovery.

Every year the PI supervises several groups of postgraduatea and undergraduate students for MSc and final year projects. We will choose some groups and instruct them to use and evaluate our toolset. Then we will show them how to refine existing functionalities and possibly implement new features.

We plan to conduct seminars and tutorials every semester, and provide financial support for our trainees to attend prestigious conferences overseas.

The Co-I will also foster a PhD student to perform interdisciplinary laboratory experiments such as cytotoxicity assays, western blotting, and oral dosage of drugs in mice.

\newpage
\linespread{0.5}
\footnotesize
\bibliographystyle{unsrtnat}
\bibliography{../refworks}

%\includefigure

\end{document}
