% Template for PLoS
% Version 1.0 January 2009
%
% To compile to pdf, run:
% latex plos.template
% bibtex plos.template
% latex plos.template
% latex plos.template
% dvipdf plos.template

\documentclass[10pt]{article}

% amsmath package, useful for mathematical formulas
\usepackage{amsmath}
% amssymb package, useful for mathematical symbols
\usepackage{amssymb}

% graphicx package, useful for including eps and pdf graphics
% include graphics with the command \includegraphics
\usepackage{graphicx}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

\usepackage{color} 

% Use doublespacing - comment out for single spacing
%\usepackage{setspace} 
%\doublespacing


% Text layout
\topmargin 0.0cm
\oddsidemargin 0.5cm
\evensidemargin 0.5cm
\textwidth 16cm 
\textheight 21cm

% Bold the 'Figure #' in the caption and separate it with a period
% Captions will be left justified
\usepackage[labelfont=bf,labelsep=period,justification=raggedright]{caption}

% Use the PLoS provided bibtex style
\bibliographystyle{plos2009}

% Remove brackets from numbering in List of References
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother


% Leave date blank
\date{}

\pagestyle{myheadings}
%% ** EDIT HERE **


%% ** EDIT HERE **
%% PLEASE INCLUDE ALL MACROS BELOW

%% END MACROS SECTION

\begin{document}

% Title must be 150 characters or less
\begin{flushleft}
{\Large
\textbf{istar: A Web Platform for Large-Scale Protein-Ligand Docking}
}
% Insert Author names, affiliations and corresponding author email.
\\
Hongjian Li$^{1,\ast}$, 
Kwong-Sak Leung$^{1}$, 
Pedro J. Ballester$^{2}$
Man-Hon Wong$^{1}$
\\
\bf{1} Department of Computer Science and Engineering, Chinese University of Hong Kong, Shatin, New Territories, Hong Kong
\bf{2} European Bioinformatics Institute, Cambridge, UK
\\
$\ast$ E-mail: JackyLeeHongJian@Gmail.com, pedro.ballester@ebi.ac.uk
\end{flushleft}

% Please keep the abstract between 250 and 300 words
\section*{Abstract}
Protein-ligand docking is a key computational method in the design of starting points for the drug discovery process. We are motivated by the desire to automate large-scale docking using our popular docking engine idock and thus have developed a publicly-accessible web platform called istar. Without tedious software installation, users can submit jobs on the fly either by using our website or by programming against our REST API. Our istar website supports 1) filtering ligands by desired molecular properties and previewing the number of ligands to dock, 2) monitoring job progress in real time, and 3) outputting free energy and ligand efficiency predicted by idock, binding affinity predicted by RF-Score, putative hydrogen bonds, and supplier information for easy purchase, three useful features commonly lacked on other online docking platforms like DOCK Blaster or iScreen. We have collected 12,171,187 ligands from the clean subset of the ZINC database, and revamped our docking engine idock to version 2.1, further improving docking speed and accuracy, introducing new functionalities, and integrating RF-Score as an alternative rescoring function. To compare idock 2.1 with the state-of-the-art AutoDock Vina 1.1.2, we have carried out a rescoring benchmark and a redocking benchmark on the 2,897 and 343 protein-ligand complexes of PDBbind v2012 refined set and CSAR NRC HiQ Set 24Sept2010 respectively, and a execution time benchmark on 12 diverse proteins and 3,000 ligands of different molecular weight. Results show that, under various scenarios, idock achieves comparable success rates while outperforming AutoDock Vina in terms of docking speed by at least 8.69 times and at most 37.51 times. When evaluated on the PDBbind v2012 core set, our istar platform combining with RF-Score manages to reproduce Pearson's correlation coefficient and Spearman's correlation coefficient of as high as 0.855 and 0.859 respectively between the experimental binding affinity and the predicted binding affinity of the docked conformation. istar is freely available at http://istar.cse.cuhk.edu.hk.

% Please keep the Author Summary between 150 and 200 words
% Use first person. PLoS ONE authors please skip this step. 
% Author Summary not valid for PLoS ONE submissions.   
%\section*{Author Summary}

\section*{Introduction}
Protein-ligand docking predicts the preferred conformation and binding affinity of a small ligand as non-covalently bound to the specific binding site of a protein. Docking can therefore be used not only to determine whether a ligand binds, but also to understand how it binds. The latter is subsequently important to improve the potency and selectivity of binding. To date, there are hundreds of docking programs \cite{493,922}. The AutoDock series \cite{597,596,595} is the most cited docking software in the research community, with over 5,000 citations according to Google Scholar. AutoDock has contributed to the discovery of several drugs, including the first clinically approved HIV integrase inhibitor \cite{1169}. Following its initial release, several parallel implementations were developed using either multithreading or computer cluster \cite{115,560,782}.

In 2009, AutoDock Vina \cite{595} was released. As the successor of AutoDock 4 \cite{596}, AutoDock Vina significantly improves the average accuracy of the binding mode predictions while running two orders of magnitude faster with multithreading \cite{595}. It was compared to AutoDock 4 on selecting active compounds against HIV protease, and was recommended for docking large molecules \cite{556}. Its functionality of semi-flexible protein docking by enabling flexibility of side-chain residues was evaluated on VEGFR-2 \cite{1084}. To further facilitate the usage of AutoDock Vina, auxiliary tools were subsequently developed, including a PyMOL \cite{1221} plugin for program settings and visualization \cite{609}, a bootable operating system for computer clusters \cite{773}, and a GUI for virtual screening on Windows \cite{1250}.

In 2011, inspired by AutoDock Vina, we developed idock 1.0 \cite{1153}, a multithreaded virtual screening tool for flexible ligand docking. idock introduces plenty of innovations, such as caching receptor and grid maps in memory to permit efficient large-scale docking, revised numerical model for much faster energy approximation, capability of automatic detection and deactivation of inactive torsions for dimensionality reduction, utilization of our lightweight thread pool to parallelize grid map creation and reuse threads, utilization of the new C++11 programming features to avoid frequent memory reallocation, and accelerated parsers for both receptors and ligands. When benchmarked on docking 10,928 drug-like ligands against HIV reverse transcriptase, idock 1.0 achieved a speedup of 3.3 in terms of CPU time and a speedup of 7.5 in terms of elapsed time on average compared to AutoDock Vina, making idock one of the fastest docking software.

Having released idock, we kept receiving docking requests from our colleagues and collaborators. They are mostly biochemists and pharmacologists, outsourcing the docking research to us after discovering pharmaceutical protein targets for certain diseases of therapeutic interest. Consequently, we had to grab the protein structure, do format conversion, define search space, set up docking parameters, and keep running idock in batch for months. Tedious enough, all the above work was done manually, resulting in very low research productivity. In order to automate large-scale protein-ligand docking using our idock, we have therefore developed a web platform called istar.

A few online docking platforms already exist. DOCK Blaster \cite{557} investigates the feasibility of full automation of protein-ligand docking. It utilizes DOCK \cite{1222} as the docking engine and ZINC \cite{532,1178} as the ligand database. It also utilizes PocketPickker (CLIPPERS) \cite{395} for binding pocket identification. iScreen \cite{899} is a compacted web server for TCM (Traditional Chinese Medicine) docking and followed by customized \textit{de novo} drug design. It utilizes PLANTS \cite{610,607,779} as the docking engine and TCM@Taiwan \cite{528} as the ligand database. It also utilizes LEA3D \cite{1223} for \textit{de novo} ligand design. FORECASTER \cite{1012} is a web interface consisting of a set of tools for the virtual screening of small molecules binding to biomacromolecules (proteins, receptors, and nucleic acids). It utilizes the flexible-target docking program FITTED \cite{602} as docking engine. Nevertheless, the above platforms neither support fine-grained ligand selection based on molecular properties, nor be able to monitor job progress in real time. They also lack straightforward output of compound suppliers, a hurdle preventing users from purchasing high-rank compounds for further wet-lab verification. We aim to address these obstacles on our istar platform. Moreover, we strongly emphasize docking efficiency, which we believe is the most crucial factor for public large-scale docking platforms, so we try every endeavor to optimize our docking engine idock. Furthermore, we adopt the robust RF-Score \cite{564} as a rescoring function for accurate prediction of binding affinity.

% You may title this section "Methods" or "Models". 
% "Models" is not a valid title for PLoS ONE authors. However, PLoS ONE
% authors may use "Analysis" 
\section*{Methods}
In the following three subsections, we introduce our fast docking engine idock, our accurate rescoring function RF-Score, and our modern web platform istar.

\subsection*{Docking engine idock}
The input to idock includes a rigid receptor, a set of flexible ligands, and a cubic box, which is used to restrict the conformational space to a particular binding site of the receptor. The output from idock includes predicted conformations and their predicted binding affinity. In a typical workflow, idock first parses the receptor and creates a thread pool to hold reusable threads. It then parses the ligands one by one, and distributes multiple independent optimization runs per ligand to the thread pool for concurrent execution. Finally it clusters the conformations from separate threads.

idock consists of two core components, a scoring function to predict binding affinity, and an optimization algorithm to explore the conformational space. idock inherits the same scoring function from AutoDock Vina. The idock score is made up of a conformation-dependent part and a conformation-independent part. The conformation-dependent part is a weighted sum of five terms over all the pairs of atoms $i$ and $j$ that can move relative to each other, excluding 1-4 interactions, i.e. atoms separated by three consecutive covalent bonds. The sum is calculated from equations \eqref{eqn:e} and \eqref{eqn:eij} where $t_i$ and $t_j$ are the atom types of $i$ and $j$ respectively, and $r_{ij}$ is their interatomic distance with a cutoff at $r_{ij}$ = 8\AA. The five terms are calculated from equations \eqref{eqn:Gauss1} to \eqref{eqn:HBonding} where $d_{ij}$ is the surface distance calculated from equation \eqref{eqn:dij} where $R_{t_i}$ and $R_{t_j}$ are the Van der Waals radii of $t_i$ and $t_j$ respectively. All the units are in \AA. The first three terms account for steric interactions, the fourth term accounts for hydrophobic effect, and the fifth term accounts for hydrogen bonding. Metal ions are treated as hydrogen bond donors. The weighting coefficients are derived from linear regression on the PDBbind \cite{529,530} v2007 refined set ($N$ = 1,300). The optimization algorithm attempts to find the global minimum of $e$ and other low-scoring conformations, which it then ranks.
\begin{equation}
\label{eqn:e}
e = \sum_{i < j} e_{ij}
\end{equation}
\begin{eqnarray}
\label{eqn:eij}
e_{ij} &=& (-0.035579) * Gauss_1(t_i, t_j, r_{ij}) \nonumber \\
       &+& (-0.005156) * Gauss_2(t_i, t_j, r_{ij}) \nonumber \\
       &+& (+0.840245) * Repulsion(t_i, t_j, r_{ij}) \nonumber \\
       &+& (-0.035069) * Hydrophobic(t_i, t_j, r_{ij}) \nonumber \\
       &+& (-0.587439) * HBonding(t_i, t_j, r_{ij})
\end{eqnarray}
\begin{equation}
\label{eqn:Gauss1}
Gauss_1(t_i, t_j, r_{ij}) = e^{-(d_{ij} / 0.5)^2}
\end{equation}
\begin{equation}
\label{eqn:Gauss2}
Gauss_2(t_i, t_j, r_{ij}) = e^{-((d_{ij} - 3) / 2)^2}
\end{equation}
\begin{equation}
\label{eqn:Repulsion}
Repulsion(t_i, t_j, r_{ij}) =
\begin{cases}
d_{ij}^2 & \text{if } d_{ij} < 0\\
0 &\text{if } d_{ij} \geq 0
\end{cases}
\end{equation}
\begin{equation}
\label{eqn:Hydrophobic}
Hydrophobic(t_i, t_j, r_{ij}) =
\begin{cases}
1 & \text{if } d_{ij} \leq 0.5\\
1.5 - d_{ij} & \text{if } 0.5 < d_{ij} < 1.5\\
0 & \text{if } d_{ij} \geq 1.5\\
\end{cases}
\end{equation}
\begin{equation}
\label{eqn:HBonding}
HBonding(t_i, t_j, r_{ij}) =
\begin{cases}
1 & \text{if } d_{ij} \leq -0.7\\
d_{ij} / (-0.7) & \text{if } -0.7 < d_{ij} < 0\\
0 & \text{if } d_{ij} \geq 0\\
\end{cases}
\end{equation}
\begin{equation}
\label{eqn:dij}
d_{ij} = r_{ij} - (R_{t_i} + R_{t_j})
\end{equation}
The conformation-dependent part can be seen as the sum of inter-molecular and intra-molecular contributions. Hence equation \eqref{eqn:e} can be rewritten into equation \eqref{eqn:inter-intra} where $e_{inter}$ is the summation over all the heavy atom pairs between receptor and ligand, and $e_{intra}$ is the summation over all the non 1-4 heavy atom pairs of ligand.
\begin{equation}
\label{eqn:inter-intra}
e = e_{inter} + e_{intra}
\end{equation}
The conformation-independent part penalizes $e_{inter}$ for ligand flexibility. The predicted free energy of the $k$th conformation for output, denoted as $e'_k$, is calculated from equation \eqref{eqn:FlexibilityPenalty} where $k$ is the subscript for conformation, $e_k$ is the conformation-dependent score of the $k$th conformation calculated from equation \eqref{eqn:e}, $e_{intra,1}$ is the $e_{intra}$ of the first, i.e. lowest-scoring conformation, $N_{ActTors}$ is the number of active torsions and $N_{InactTors}$ is the number of inactive torsions of the ligand. Note that $e_{intra,1}$, rather than $e_{intra,k}$, is subtracted in order to preserve the ranking.
\begin{equation}
\label{eqn:FlexibilityPenalty}
e'_k = \frac{e_k - e_{intra,1}}{1 + 0.05846 * (N_{ActTors} + 0.5 * N_{InactTors})}
\end{equation}
On one hand, in order to fast evaluate $e_{ij}$, idock precalculates all its possible values. Note that $e_{ij}$ is essentially a function of three variables, namely $t_i$, $t_j$, and $r_{ij}$, which have known lower and upper bounds. There are 15 heavy atom types implemented in idock, the pair of $t_i$ and $t_j$ can thus have 120 (=15*16/2) different combinations. Since $r_{ij}$ is cut off at 8\AA, idock uniformly samples 16,384 points in the range [0, 8] and precalculates their $e_{ij}$ from equation \eqref{eqn:eij}. Subsequently, given a combination of $t_i$, $t_j$ and $r_{ij}$, idock approximates the true value of $e_{ij}$ by table lookup rather than linear interpolation as used in AutoDock Vina.

On the other hand, in order to fast evaluate $e_{inter}$, idock precalculates all its possible values by building grid maps. A grid map of atom type \textit{t} is constructed by placing virtual probe atoms of atom type \textit{t} along the X, Y, Z dimensions of the search box at a certain granularity. The $e_{inter}$ value of these probe atoms are precalculated from equation \eqref{eqn:eij}. Subsequently, given a sampled conformation, idock approximates the true values of $e_{inter}$ of ligand heavy atoms by table lookup rather than linear interpolation as used in AutoDock Vina. In fact, when we profiled AutoDock Vina, its linear interpolation of the 8 nearest corner probe atoms turned out to be a performance bottleneck because it involves 8 readings, 12 subtractions, 24 multiplications, and 7 additions. The grid granularity is hard-coded to be a coarse value of 0.375\AA\ in AutoDock Vina, while in idock it is exposed as a program option for users to adjust accordingly and has a default fine value of 0.15625\AA.

Likewise in AutoDock Vina, idock also uses Broyden-Fletcher-Goldfarb-Shanno (BFGS) \cite{786} Quasi-Newton method for local optimization. In each BFGS iteration, a conformational mutation and a line search are taken, with each sampled conformation being accepted according to the Metropolis criterion. The number of iterations correlates to the complexity of the ligand regarding number of heavy atoms and number of torsions. BFGS approximates the inverse Hessian matrix, i.e. it uses not only the value of the scoring function but also its gradient, which are the derivatives of the scoring function with respect to the position, orientation and torsions of the ligand. Although both programs share similar optimization algorithms, their internal implementations differ. In idock, the BFGS local optimization stops if and only if no appropriate step length can be obtained by line search, thus increasing the probability of finding optimal local minimums. More optimization runs with fewer number of BFGS iterations are executed, better balancing high conformational diversity and short execution time.

idock introduces a novel feature that can automatically detect and deactivate certain torsions which are activated in the input file but indeed have no impact on the overall scoring, such as hydroxyl group \textemdash{OH}, amine group \textemdash{NH$_2$} or methyl group \textemdash{CH$_3$}, because they only rotate the hydrogens and thus have no contributions to the idock score. idock is capable of re-classifying them as inactive torsions during parsing, thus reducing the dimension of variables to optimize in subsequent BFGS iterations.

idock implements a lightweight thread pool in order to reuse threads and maintain a high CPU utilization throughout the entire docking procedure. The thread pool parallelizes the precalculation of scoring function, the creation of grid maps, and the execution of optimization runs. The threads compete for tasks. The thread that completes its current task will automatically fetch a pending one to execute until all are done. Synchronization is implemented to ensure the full completeness of tasks and availability of results.

idock encapsulates many more improvements, such as gzip/bzip2 support in both ligand input and output, automatic docking recovery from the previous stopping point, fast parsers for both receptor and ligand, and memory reallocation reduction via modern C++11 programming features. Please refer to its change log at https://github.com/HongjianLi/idock for a complete list of new features.

\subsection*{Scoring function RF-Score}
RF-Score \cite{564} is a member of a new class of scoring functions that use non-parametric machine learning approach to predict binding affinity in an entirely data-driven manner. RF-Score has been rigorously shown \cite{564,908} to perform better than 16 classical scoring functions in ranking protein-ligand complexes according to predicted binding affinity. It has also been shown to be useful in the discovery of new molecular scaffolds in antibacterial hit identification \cite{1281}.

RF-Score is the first application of Random Forests \cite{1309} to predicting protein-ligand binding affinity. In RF-Score, each feature comprises the number of occurrences of a particular protein-ligand atom type pair interacting within a certain distance range. Four common atom types for the protein (i.e. C,N,O,S) and nine common atom types for the ligand (i.e. C,N,O,F,P,S,Cl,Br,I) constitute a vector of 36 features, and the distance cutoff is chosen to be as sufficiently large as 12\AA\ to implicitly capture solvation effects.

The original version of RF-Score \cite{564} is trained on PDBbind v2007 refined set less the core set ($N$ = 1,105) using the CART algorithm \cite{1310}. It grows each binary tree without pruning from a bootstrap sample of the training data. The final prediction is the arithmetic mean of the individual predictions of all the trees in the forest.

We have re-trained the RF-Score on PDBbind v2012 refined set ($N$ = 2,897) for prospective prediction purpose, and integrated it into our istar platform as an alternative option to re-score and re-rank predicted conformations. We have also implemented a consensus score as the average effect of idock score and RF-Score. Mathematically speaking, equations \eqref{eqn1} to \eqref{eqn3} relate equilibrium constant $K_{eq}$ and dissociation constant $K_d$ with Gibbs free energy $\Delta G$, where $R$ is gas constant ($R = 1.9858775 \times 10^{-3} kcal/mol$) and $T$ is absolute temperature.
\begin{equation}
\label{eqn1}
\Delta G = -RT\ln K_{eq}
\end{equation}
\begin{equation}
\label{eqn2}
K_d = \frac{1}{K_{eq}}
\end{equation}
\begin{equation}
\label{eqn3}
pK_d = -\ln K_d
\end{equation}

Assuming $T = 298.15K$ at room temperature, plugging equations \eqref{eqn2} and \eqref{eqn3} into \eqref{eqn1} yields
\begin{equation}
\label{eqn4}
pK_d = -0.73349480509 \cdot \Delta G
\end{equation}

Equation \eqref{eqn4} transforms the predicted free energy output by idock in $kcal/mol$ into binding affinity in $pK_d$ unit. The consensus score is thus defined in equation \eqref{eqn5} so that it directly reflects the predicted potency in $pK_d$ unit.
\begin{equation}
\label{eqn5}
ConsensusScore = 0.5 \times (-0.73349480509 \cdot idockScore + RFScore)
\end{equation}

\subsection*{Web platform istar}
Figure \ref{Architecture} shows the overall architecture of istar. There are five major components: a website, a web server, a database management system, several workstations, and a network file system. Under typical circumstances, a user browses our website and submits a job. The web server first validates user input and then saves it into the database. Several workstations keep running daemons in the background, fetching jobs from the database and performing protein-ligand docking. Upon completion, they send a notification email to the user and write the result to the network file system, which is cached as static content by the web server. The user again browses our website to download result or monitor job progress. Our web server also supports REST API for developers to program against.

On our istar website, the first section displays summary of existing jobs and the second section allows new job submission. A job comprises compulsory fields and optional fields. Compulsory fields include a receptor in PDBQT format as used by idock and the AutoDock series, a search space defined by a cubic box, a brief description about the job, and an email to receive completion notification. Optional fields include nine ligand filtering conditions and ligand sorting criterion. The nine ligand filtering conditions are molecular weight, partition coefficient xlogP, apolar desolvation, polar desolvation, number of hydrogen bond donors, number of hydrogen bond acceptors, topological polar surface area tPSA, net charge, and number of rotatable bonds. These nine molecular descriptors are directly retrieved from our data source, i.e. the ZINC database \cite{532,1178}, in which the nine descriptors are already precalculated. Note that although molecular mass in Dalton unit may be a more appropriate descriptor than molecular weight in g/mol unit, we stick to the latter in order to maintain consistency with ZINC, in which the g/mol unit is used for molecular weight. The ligand sorting criterion can be either idock score, RF-Score, or their consensus score.

We have collected 12,171,187 ligands at pH 7 in mol2 format from version 2012-04-06 of the All Clean subset the ZINC database \cite{532,1178} with explicit permission of its major developer and maintainer. The All Clean subset is constituted by applying strict filtering rules (http://blaster.docking.org/filtering), e.g. aldehydes and thiols have been removed. We have then converted the entire 12 million ligands in batch into PDBQT format.

istar supports ligand selection by desired molecular properties in a fine-grained manner and previewing the number of ligands to dock in real time (Figure \ref{Slider}). Users can move the nine sliders to filter ligands in the form of closed intervals. Only the ligands satisfying all the nine filtering conditions will be docked. Because of the relationship of logical and, in order to nullify a specific filtering condition, one may expand its closed interval to cover the entire possible range. We have set up default values of the lower and upper bounds of the nine molecular properties for novices to get started easily.

After jobs are submitted and queued in the server, it is the daemon that indeed performs protein-ligand docking. A daemon is a program running in the background and doing some kind of jobs. Based on the offline version of idock, we have derived a customized daemon specifically for use in the istar environment.

Notably, our idock daemon performs 2-phase docking. In phase 1, the daemon performs coarse but fast docking without writing any conformations, aiming to quickly shortlist a few thousand candidate compounds out of the large amount of user-selected ligands. The coarse docking mode behaves similarly to the offline version of idock in the sense that they both execute 32 optimization runs per ligand, except that the daemon writes no conformations in order to save I/O cost, and it exploits slice-level parallelism. The entire 12 million ligands are evenly subdivided into 100 slices, with each slice covering 0.12 million ligands. The 100 slices are then distributed to idle workstations to achieve parallel docking. Therefore even a single job can benefit from multiple CPU cores across multiple workstations, ensuring all the computational resources are fully utilized. In phase 2, the daemon performs fine but slow docking, writing as many conformations as possible for users to download and aiming to refine the predicted conformations and binding affinity of candidate compounds, i.e. the top 1,000 ligands ranked in phase 1. The fine docking mode increases the number of optimization runs from 32 to 128 in order to explore the conformational space more exhaustively, but requires 4x execution time in return. It exploits job-level parallelism instead, i.e. the phase 2 of multiple jobs can be distributed to idle workstations for parallel docking, but the phase 2 itself cannot be further split into slices. In this way, the daemon utilizes all the CPU cores of one single workstation. It is certainly possible to implement slice-level parallelism in phase 2, but the implementation would become far too sophisticated. Most importantly, the current design can already hide the pipelining latency because given a set of $N$ workstations and a queue of two or more jobs, one workstation executes phase 2 of the first job in parallel while all the other $N-1$ workstations execute phase 1 of the second job in parallel. We have done a ranking benchmark to confirm that phase 1 is able to capture most of the ligands that deserve to pass to phase 2.

istar supports monitoring job progress in real time (Figure \ref{Progress}). We have composed a timer to automatically fetch and report the latest job progress every second without page refresh. Users can thus have a rough estimation in advance of how long the jobs will take and when the jobs will complete. This feature is particularly handy when the jobs are long running, which is usually the case of large-scale docking.

istar outputs verbose information in PDBQT format (Figure \ref{OutputPDBQT}). The first REMARK line describes the ZINC ID, molecular weight (g/mol), partition coefficient xlogP, apolar desolvation (kcal/mol), polar desolvation (kcal/mol), number of hydrogen bond donors, number of hydrogen bond acceptors, topological polar surface area tPSA ($\AA^2$), net charge, and number of rotatable bonds of a selected ligand. The second REMARK line describes the number of suppliers followed by their names, which conform to the nomenclature as used by ZINC. For each predicted conformation, the REMARK lines describe the free energy and ligand efficiency predicted by idock, putative hydrogen bonds, binding affinity predicted by RF-Score, and consensus score in $pK_d$ or $pK_i$ unit. Columns 71 to 76 of the ATOM lines describe the predicted free energy of each atom. The individual atom contribution to the overall score facilitates the detection of protein-ligand interaction hotspots, and thus assists in \textit{de novo} ligand design.

% Results and Discussion can be combined.
\section*{Results}
We evaluated and compared the latest versions of idock and AutoDock Vina from the perspectives of rescoring, redocking, and execution time on three datasets, which are PDBbind \cite{529,530}, CSAR \cite{857,960} and ZINC \cite{532,1178}.

The PDBbind v2012 dataset contains a diverse collection of experimentally determined protein-ligand complexes carefully selected from PDB (Protein Data Bank) \cite{540,537}. For each complex, the experimental binding affinity (either dissociation constant $K_d$, inhibition constant $K_i$, or half maximal inhibitory concentration $IC_{50}$) is manually collected from its primary literature reference, thus resulting in the general set of 9,308 complexes. Out of them, the complexes with a resolution of 2.5\AA\ or better, with known $K_d$ or $K_i$ values, and with ligand containing merely the common heavy atoms (i.e. C, N, O, F, P, S, Cl, Br, I) are filtered to constitute the refined set of 2,897 complexes. These complexes are then clustered by protein sequence similarity using BLAST at a cutoff of 90\%, and for each of the 67 resulting clusters with at least five complexes, the three complexes with the highest, median and lowest binding affinity are selected to constitute the core set of 201 complexes, whose experimental binding affinity spans 10 $pK_d$ or $pK_i$ units.

The CSAR (Community Structure Activity Resource) NRC HiQ Set 24Sept2010 contains 343 diverse protein-ligand complexes and their binding affinity spans 12 $pK_d$ units. They are selected from existing PDB \cite{540,537} entries which have binding affinity ($K_d$ or $K_i$) in Binding MOAD \cite{517,518}, augmented with entries from PDBbind \cite{529,530}.

The ZINC database contains over 21 million purchasable small molecules in popular MOL2 and SDF formats.

We executed idock x86\_64 v2.1 and AutoDock Vina x86 v1.1.2 on desktop computers with Intel Core i5-2400 CPU @ 3.10GHz and 4GB DDR3 RAM under Mac OS X 10.7.4 Build 11E53. Arguments to both programs were left as default. By default, both programs output 9 predicted conformations per ligand.

\subsection*{Rescoring Benchmark}
Rescoring refers to predicting the binding affinity as close to the experimental binding affinity as possible given a crystal protein-ligand complex. Table \ref{ScoringFunctionComparison} compares 21 scoring functions on PDBbind v2007 core set ($N$ = 195). RF-Score \cite{564}, ID-Score \cite{1305}, SVR-Score \cite{1295} and X-Score \cite{573} are the only scoring functions whose training set do not overlap with the PDBbind v2007 core set. In terms of Pearson's correlation coefficient, RF-Score performed the best, while AutoDock Vina and idock ranked 7th and 8th respectively, already outperforming the majority of commercial scoring functions.

Figure \ref{PDBbind2012Correlations} plots the pairwise correlations amongst experimental binding affinity and predicted binding affinity by RF-Score, AutoDock Vina and idock on PDBbind v2012 \cite{529,530} refined set ($N$ = 2,897). Since both AutoDock Vina and idock are trained on the PDBbind v2007 refined set ($N$ = 1,300), in order to make a fair comparison, in this benchmark we have re-trained RF-Score on the same training set. On one hand, the re-trained RF-Score managed to reproduce the binding affinity accurately with Pearson's correlation coefficient $R_p$ = 0.765, Spearman's correlation coefficient $R_s$ = 0.755, root mean square error $RMSE$ = 1.26, and standard deviation $SD$ = 1.26. On the other hand, although AutoDock Vina and idock claimed to do well in conformation prediction, they could not predict binding affinity very accurately ($R_p$ = 0.466, $R_s$ = 0.464, $RMSE$ = 1.74, $SD$ = 1.74 for AutoDock Vina, and $R_p$ = 0.451, $R_s$ = 0.453, $RMSE$ = 1.75, $SD$ = 1.75 for idock), a very common obstacle in the entire computational chemistry community. As expected, the correlation between binding affinity predicted by AutoDock Vina and idock is very close to 1 because of their identical scoring function but different numerical approximation methods \cite{1153}. As can be seen from Figure \ref{CSAR2010Correlations}, the above observations also apply to the results on the CSAR NRC HiQ Set 24Sept2010 ($N$ = 343) \cite{857,960}.

\subsection*{Redocking Benchmark}
Redocking refers to randomizing the crystal ligand conformation in a protein-ligand complex and trying to dock the randomized conformation back to its crystal conformation as close as possible. For the redocking benchmark, we used the PDBbind v2012 \cite{529,530} refined set ($N$ = 2,897), the PDBbind v2011 refined set ($N$ = 2,455), and the CSAR NRC HiQ Set 24Sept2010 ($N$ = 343) \cite{857,960}, because they are the latest versions and contain the largest number of high-quality and diverse protein-ligand structures. We wrote a script to automatically define the search box first by finding the smallest cubic box that covers the entire ligand and then by extending the box by 10\AA\ in all the three dimensions. Note that the 2rio entry of PDBbind contains two strontium ions, which are supported by idock but not by AutoDock Vina, we manually removed them before invoking AutoDock Vina.

Figures \ref{Redocking1B8N}, \ref{Redocking4TMN}, \ref{Redocking1PKX} and \ref{Redocking3HV8} visualize the redocking results of four protein-ligand complexes selected from the PDBbind v2012 refined set. We used root mean square deviation $RMSD$ to measure the closeness between two conformations. The lower the $RMSD$ is, the closer the two conformations are. Usually the $RMSD$ value is calculated between the crystal conformation and the docked conformation. Very often the $RMSD$ of 2.0\AA\ is regarded as the positive control for correct bound structure prediction. In Figure \ref{Redocking1B8N} whose protein target is purine nucleoside phosphorylase (PDB ID 1B8N), both programs managed to predict a conformation sufficiently close to that of the co-crystallized ligand. In Figure \ref{Redocking4TMN} whose protein target is thermolysin (PDB ID 4TMN), both programs failed, probably due to the presence of a zinc ion in the binding site. In Figure \ref{Redocking1PKX} whose protein target is bifunctional purine biosynthesis protein PURH (PDB ID 1PKX), idock succeeded but AutoDock Vina failed. In Figure \ref{Redocking3HV8} whose protein target is of FimX (PDB ID 3HV8), AutoDock Vina succeeded but idock failed.

Table \ref{SuccessRate} shows the success rates of idock and AutoDock Vina under various conditions regarding the $RMSD$ values between the crystal and docked conformations. Given a redocking case, $RMSD_i (i = 1,2,...,9)$ refers to the $RMSD$ value between the crystal conformation and the $i$th docked conformation, i.e. the one with the $i$th highest predicted binding affinity, while $RMSD_{min}$ refers to the $RMSD$ value between the crystal conformation and the closest docked conformation, i.e. the one with the minimum $RMSD$ value. $RMSD_{min} = \displaystyle\min_{i}RMSD_i\ (i = 1,2,...,9)$. The condition $RMSD_1$ = $RMSD_{min}$ therefore tests for how many percent the docked conformation with the highest predicted binding affinity actually turns out to be the closest one among the 9 predicted conformations. It can be seen that the success rates of idock are comparable to, albeit slightly lower than, AutoDock Vina, and the success rates on the CSAR NRC HiQ Set 24Sept2010 are consistently higher than the PDBbind v2012 and v2011 refined sets, probably because the scoring function performs well on carefully refined structures. Using a RMSD value of 2.0\AA, a publicly accepted positive control for correct bound structure prediction, both programs managed to predict a conformation sufficiently close to that of the co-crystallized ligand as the first conformation in over half of the cases, without any manual tweaking of the protein model.

Both programs were also evaluated on the PDBbind v2012 core set ($N$ = 201). Figure \ref{Program-NRB} plots the impact of rotatable bonds of the ligand on the success rates. Both programs tend to do well when the ligand contains fewer than 10 rotatable bonds. Figure \ref{Program-NIONS} plots the impact of metal ions in the binding site on the success rates. Both programs tend to do well when the binding site contains no metal ions. Figure \ref{pK-idockConf1idock} shows the scatter plot of the highest predicted binding affinity of the 9 docked conformations output by idock against the experimental binding affinity. The weak correlation and large deviation ($R_p$ = 0.502, $R_s$ = 0.530, $RMSE$ = 1.31, $SD$ = 1.32) reflect the limitation of using idock alone as scoring function. After adopting the maximum RF-Score of the 9 docked conformations as predicted binding affinity, the correlation improves (Figure \ref{pK-idockConfsRFScoreMax}, $R_p$ = 0.815, $R_s$ = 0.817, $RMSE$ = 0.75, $SD$ = 0.76). Moreover, since for 50\% probability the docked conformation with the highest predicted binding affinity indeed turns out to be the closest to the crystal conformation (i.e. $RMSD_1$ = $RMSD_{min}$), using RF-Score to re-score the conformation with $RMSD_1$ leads to even better prediction (Figure \ref{pK-idockConf1RFScore}, $R_p$ = 0.855, $R_s$ = 0.859, $RMSE$ = 0.73, $SD$ = 0.73).%Figure \ref{VinaConf1RMSD-idockConf1RMSD} shows the $RMSD_1$ values for idock plotted against those for AutoDock Vina. Many points fall onto the diagonal, suggesting that both programs tend to predict similar conformations.

\subsection*{Execution Time Benchmark}
We collected 12 diverse proteins from the PDB (Protein Data Bank) database \cite{540,537}, and 1000 ligands with a molecular weight of 200-300g/mol, 1000 ligands with a molecular weight of 300-400g/mol, and 1000 ligands with a molecular weight of 400-500g/mol from the All Clean subset of the ZINC database \cite{532,1178}. The 3,000 ligands were docked against the 12 proteins by AutoDock Vina and idock. Since AutoDock Vina can dock only one ligand in a run, three bash scripts containing 1,000 lines were executed instead, with each line being an execution of AutoDock Vina to dock one single ligand. The GNU Time utility v1.7 was used as a profiler.

Table \ref{ExecutionTime} compares the CPU time and elapsed time of AutoDock Vina and idock. The execution time varied a lot from protein to protein and from molecular weight set to molecular weight set. In conclusion, idock outperformed AutoDock Vina by at least 8.69 times and at most 37.51 times, making idock particularly ideal for large-scale docking, as is the case of istar.

\subsection*{2-Phase Ranking Benchmark}
To verify that phase 1 is able to capture the majority of ligands that deserve to pass to phase 2, we used E3 ubiquitin ligase as protein target and selected 1,107 ligands to dock. In phase 1, all the 1,107 ligands were docked by creating 32 optimizations runs per ligand, and then were ranked according to their idock score. The top 1,000 ligands were passed to phase 2 for refinement by creating 128 optimizations runs per ligand, and then were also ranked according to their idock score. The rankings in both phases agree, resulting in a Spearman correlation coefficient of 0.954.

%\subsection*{Benchmark of Enrichment}
%Consider three basic cases related to the “early recognition” problem. (1) half of the actives are retrieved at the very beginning of the rank-ordered list and the other half at the end; (2) the actives are randomly distributed all across the ranks; (3) all of the actives are retrieved in the middle of the list. In all three cases, the ROC metric is 1/2 when, in terms of the “early recognition”, case 1 is clearly better than case 2, which is also significantly better than case 3.
%Despite the increasing numbers of performance evaluations of ranking methods in the context of VS, there is still no consensus on the metrics used to analyze the results. Area under the curve metrics such as ROC are not suited to the “early recognition” problem. Metrics such as the area under the accumulation curve, the average rank, and the area under the ROC curve dramatically fail to discriminate among three trivial cases outlined in the Introduction that must be correctly ranked by any metric intended to be usefully applied to VS.
%BEDROC was proposed \cite{490}. An $\alpha$ value of 20 contributes to 80\% of the total BEDROC score at 8\% of the ordered rank list, it is thus suggested as a reasonable choice for a VS evaluation.

\section*{Discussion}
Docking is the computational method that investigates how a ligand binds to a protein, and predicts their binding affinity. Hence docking is useful in elaborating inter-molecular interactions and enhancing the potency and selectivity of binding in subsequent phases of the drug discovery process.

In this study, we report a web platform called istar to automate large-scale protein-ligand docking using our popular docking engine idock. Since the initial release of idock, we have been further improving its docking speed and robustness. Compared to AutoDock Vina, our idock features a new numerical model in approximation of the scoring function, replacing slow linear interpolation by fast table lookup. It encapsulates a unique feature that can safely deactivate certain torsions to reduce the dimension of variables. It also implements an efficient thread pool to parallelize multiple components of the program and maintain a high CPU utilization. Results show that idock managed to predict a conformation sufficiently close to that of the co-crystallized ligand as the first conformation in over half of the test cases across a number of diverse datasets, and it outperformed AutoDock Vina by an order of magnitude in terms of docking efficiency at no significant cost of accuracy. It is worthwhile to highlight that in order to use idock, the input protein model requires no manual preprocessing at all except PDB-to-PDBQT format conversion, which can be automated by the Python scripts of MGLTools \cite{596}.

We examine two possible reasons that might cause idock to fail in some test cases. They are the number of rotatable bonds of the ligand (Figure \ref{Program-NRB}) and the number of metal ions in the binding site (Figure \ref{Program-NIONS}). On one hand, a large number of rotatable bonds implies a high dimension of variables to optimize. idock has a higher chance to succeed when the ligand consists of fewer than 10 rotatable bonds. On the other hand, all kinds of metal ions are simply treated as hydrogen bond donors in the idock score, which might not thoroughly accounts for their solvation effects and other possible interactions. idock has a higher chance to succeed when the binding site consists of no metal ions.

Although idock performs well in conformation prediction, it displays its weakness in binding affinity prediction. In contrast, RF-Score, a new scoring function that circumvents the need for problematic modelling assumptions via non-parametric machine learning, has been recently shown to obtain the best scoring performance among 16 classical scoring functions on PDBbind v2007 core set ($N$ = 195) \cite{564}. We have therefore integrated a revised version of RF-Score as an alternative re-scoring function. We have re-trained RF-Score on the entire PDBbind v2012 refined set ($N$ = 2,897) for prospective prediction purpose. Results show that using RF-Score to re-score the predicted conformations leads to a much better prediction with $R_p$ = 0.855, $R_s$ = 0.859, $RMSE$ = 0.73, and $SD$ = 0.73. We have successfully demonstrated that RF-Score could be a particularly effective re-scoring function for docking purposes.

To compile a more complete list of scoring functions benchmarked on the PDBbind v2007 core set ($N$ = 195) into Table \ref{ScoringFunctionComparison}, we have extracted the performance results for 19 scoring functions from \cite{1313,564,1305,1295}, and reported the results for AutoDock Vina and idock on the same test set in this study. This procedure has a number of advantages. Evaluating all the scoring functions on the same test set under the same conditions guarantees a fair and objective comparison. Using a common existing benchmark can also ensure the optimal application of such functions by their authors and avoid the danger of constructing an in-house benchmark on which unrealistically high performance might be produced. Moreover, future scoring functions can be unambiguously incorporated into this comparative assessment. Notably, the top four scoring functions, namely RF-Score \cite{564}, ID-Score \cite{1305}, SVR-Score \cite{1295} and X-Score \cite{573}, are the only scoring functions whose training set do not overlap with the PDBbind v2007 core set. The prediction power of RF-Score is already superior to many scoring functions in commercial docking software. In terms of implementation complexity, a descriptor in RF-Score is just the occurrence count of a particular protein-ligand atom type pair interacting within a certain distance range, while a descriptor in ID-Score can be as mathematically demanding as, for instance, calculating the cosine value of the bond angle between a hydrogen bond donor and a hydrogen bond acceptor. This again demonstrates the adaptiveness of RF-Score to various applications.

One may argue that although the scoring functions are evaluated on the same test set, their training sets are not identical. Besides, the PDBbind v2007 core set consists of merely 195 complexes, which might not cover sufficient protein-ligand diversity from the perspective nowadays. To address this issue, we re-trained RF-Score on the PDBbind v2007 refined set ($N$ = 1,300), on which AutoDock Vina and idock were also trained, and we expanded the test set to the much larger PDBbind v2012 refined set ($N$ = 2,897). The results of Figure \ref{PDBbind2012Correlations} show that all the performance gain ($R_p$ = 0.765, $R_s$ = 0.755, $RMSE$ = 1.26, $SD$ = 1.26 for RF-Score versus $R_p$ = 0.451, $R_s$ = 0.453, $RMSE$ = 1.75, $SD$ = 1.75 for idock) is guaranteed to come from the scoring function characteristics, ruling out any influence of using different training sets on performance.

To derive an idock daemon specifically for use in the istar environment, we have made notable customizations to its offline version. Our idock daemon introduces 2-phase docking. Ligands are docked in a coarse manner in phase 1, and are then refined in a fine manner in phase 2. We have performed a test to show that the rankings of the top ligands in both phases are highly correlated. Such a 2-phase docking methodology can remarkably reduce job execution time while avoiding the risk of filtering out potentially promising compounds, resulting in a low false negative rate.

To design the istar platform in a user-friendly way, we have utilized state-of-the-art web and database technologies. On istar, there are over 12 million ready-to-dock ligands collected from ZINC \cite{532,1178}. These ligands come with supplier information for easy purchase, and they can be filtered by nine molecular properties in a fine-grained manner. The number of ligands to dock can also be previewed in real time. The jobs are transparently split into slices for parallel docking across multiple workstations, and the job progress can be monitored in real time in a browser so that users can have a rough estimation of how long the job will take and when the job will complete. Additionaly, our web server supports REST API so that developers can easily submit multiple jobs in batch. Automation is the major reason of submitting jobs to istar instead of running idock locally on one's computer. With istar at hand, users need not to write special scripts to fetch ligands from some sources, to implement parallelism, or to invoke RF-Score externally by themselves. Users can therefore concentrate on the docking results and subsequent analysis rather than the docking process itself.

We compare our istar to DOCK Blaster \cite{557}, an expert system created to investigate the feasibility of full automation of large-scale protein-ligand docking. It uses DOCK \cite{1222} as the docking engine and ZINC \cite{532,1178} as the ligand repository. Although DOCK is open source, DOCK Blaster itself is not open source. Given the structure of a target protein, both istar and DOCK Blaster can dock and score a large set of ligands against the target protein and provide a ranked list which users may review and prioritize for purchase and wet-lab testing. From the perspective of binding site indication, istar relies on a user-supplied cubic box as used in the well-known AutoDock series, while DOCK Blaster chooses a site by either a docked ligand or some binding site residues. From the perspective of ligand selection, istar features ligand filtering by nine desired molecular properties in a fine-grained fashion, while DOCK Blaster predefines several subsets either by property, by vendor, or by user. From the perspective of documentation and user manual, the istar website presents graphical tutorials on how to prepare a receptor in PDBQT format with MGLTools \cite{596}, and how to define a search space with MGLTools \cite{596}, Chimera \cite{1219} or PyMOL \cite{1221}, while DOCK Blaster deploys a wiki with very rich contents covering all the procedures of DOCK Blaster. As extra features, DOCK Blaster makes use of PocketPickker (CLIPPERS) \cite{395} for binding pocket identification, and it allows the input of known active and inactive binders as heuristic information for docking. In summary, although istar and DOCK Blaster share the identical motivation of automating large-scale protein-ligand docking, their internal implementations and methodologies differ greatly. Users are encouraged to utilize both istar and DOCK Blaster to reach a consensus of promising candidate ligands for purchase.

At the moment, we have deployed a machine with Intel Xeon W3520 @ 2.66 GHz and 8GB DDR3 SDRAM to run the web server, and two identical virtual machines with Intel Xeon E5620 @ 2.40 GHz and 8GB DDR3 SDRAM to run the idock daemons. We have mounted a 3TB hard disk into our network file system to store docking jobs and results. Due to limited budget, we cannot offer as much hardware resource as DOCK Blaster (i.e. 700 CPU cores plus 20TB RAID-6 storage). However, we emphasize full reproducibility and we have released istar under a permissive open source license so that anyone who possesses sufficient hardware resource is welcome to deploy a copy of istar to his/her own infrastructure with no charge.

\section*{Availability}
We emphasize full reproducibility. Both idock and istar are free and open source under Apache License 2.0. For idock, its C++ source code, precompiled executables for 32-bit and 64-bit Linux, Windows, Mac OS X, FreeBSD and Solaris, 13 docking examples, and a doxygen file for generating API documentations are available at https://github.com/HongjianLi/idock. For istar, its C++ and JavaScript source code and REST API documentation are available at https://github.com/HongjianLi/istar. Our istar website is running at http://istar.cse.cuhk.edu.hk. It has been tested successfully in Chrome 19+, Firefox 12+, IE 9+, Safari 5+ and Opera 12+.

% Do NOT remove this, even if you are not including acknowledgments
\section*{Acknowledgements}
We thank Professor John J. Irwin for granting us permission to use ZINC \cite{532,1178} with three conditions as stated on our istar website http://istar.cse.cuhk.edu.hk/idock.
%\begin{enumerate}
%\item We shall provide links to http://zinc.docking.org/substance/zincid for top hits so that users can seek for the most current purchasing information at ZINC's official website.
%\item We shall limit the number of top hits for download to 1000 ligands from a single job.
%\item We shall update our ligands when ZINC data is updated so that users can benefit from the most current ligand data.
%\end{enumerate}

%\section*{References}
% The bibtex filename
\bibliography{../refworks}

\section*{Figure Legends}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=4in]{Architecture.eps}
\end{center}
\caption{
{\bf The overall architecture of istar.} There are five major components: a website, a web server, a database management system, several workstations, and a network file system.
}
\label{Architecture}
\end{figure}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=4in]{Slider.eps}
\end{center}
\caption{
{\bf istar supports filtering ligands with molecular properties in a fine-grained manner and previewing the number of ligands to dock in real time.} Users can move the nine sliders to filter ligands in the form of closed intervals.
}
\label{Slider}
\end{figure}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=4in]{Progress.eps}
\end{center}
\caption{
{\bf istar supports monitoring job progress in real time.} Users can thus have a rough estimation in advance of how long the jobs will take and when the jobs will complete.
}
\label{Progress}
\end{figure}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=4in]{OutputPDBQT.eps}
\end{center}
\caption{
{\bf istar writes verbose output to file in PDBQT format.} The REMARK lines describe the ZINC ID, molecular properties and suppliers of a ligand. For each predicted conformation, the REMARK lines also describe the free energy and ligand efficiency predicted by idock, putative hydrogen bonds, binding affinity predicted by RF-Score, and consensus score in $pK_d$ or $pK_i$ unit. Columns 71 to 76 of the ATOM lines describe per-atom free energy predicted by idock.
}
\label{OutputPDBQT}
\end{figure}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=4in]{PDBbind2012Correlations.eps}
\end{center}
\caption{
{\bf Pairwise correlations of experimental binding affinity and predicted binding affinity by RF-Score, AutoDock Vina and idock on the PDBbind v2012 refined set ($N$ = 2,897).} Along the diagonal from top left to bottom right are the histogram distributions of experimental binding affinity and predicted binding affinity by RF-Score, AutoDock Vina, and idock, respectively. Values are in $pK_d$ or $pK_i$ unit. The three scoring functions are all trained on the PDBbind v2007 refined set ($N$ = 1,300). $R_p$ = 0.765, $R_s$ = 0.755, $RMSE$ = 1.26, $SD$ = 1.26 for RF-Score, $R_p$ = 0.466, $R_s$ = 0.464, $RMSE$ = 1.74, $SD$ = 1.74 for Vina, and $R_p$ = 0.451, $R_s$ = 0.453, $RMSE$ = 1.75, $SD$ = 1.75 for idock.
}
\label{PDBbind2012Correlations}
\end{figure}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=4in]{CSAR2010Correlations.eps}
\end{center}
\caption{
{\bf Pairwise correlations of experimental binding affinity and predicted binding affinity by RF-Score, AutoDock Vina and idock on the CSAR NRC HiQ Set 24Sept2010 ($N$ = 343).} Along the diagonal from top left to bottom right are the histogram distributions of experimental binding affinities and predicted binding affinities by RF-Score, AutoDock Vina, and idock, respectively. Values are in $pK_d$ or $pK_i$ unit. The three scoring functions are all trained on the PDBbind v2007 refined set ($N$ = 1,300). $R_p$ = 0.801, $R_s$ = 0.795, $RMSE$ = 1.34, $SD$ = 1.34 for RF-Score, $R_p$ = 0.595, $R_s$ = 0.612, $RMSE$ = 1.79, $SD$ = 1.79 for Vina, and $R_p$ = 0.597, $R_s$ = 0.613, $RMSE$ = 1.79, $SD$ = 1.79 for idock.
}
\label{CSAR2010Correlations}
\end{figure}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=4in]{Redocking1B8N.eps}
\end{center}
\caption{
{\bf Redocking result of PDB ID 1B8N.} The protein target is purine nucleoside phosphorylase. The crystal ligand conformation is rendered in green. The conformation predicted by Vina is rendered in red. The conformation predicted by idock is rendered in blue. The same color scheme applies to the subsequent three redocking cases. $RMSD$ = 0.14\AA\ for Vina, and $RMSD$ = 0.13\AA\ for idock. Both methods managed to predict a conformation sufficiently close to that of the co-crystallized ligand.
}
\label{Redocking1B8N}
\end{figure}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=4in]{Redocking4TMN.eps}
\end{center}
\caption{
{\bf Redocking result of PDB ID 4TMN.} The protein target is thermolysin. $RMSD$ = 8.40\AA\ for Vina, and $RMSD$ = 9.91\AA\ for idock. Both methods failed to predict a conformation sufficiently close to that of the co-crystallized ligand, probably due to the presence of a zinc ion in the binding site.
}
\label{Redocking4TMN}
\end{figure}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=4in]{Redocking1PKX.eps}
\end{center}
\caption{
{\bf Redocking result of PDB ID 1PKX.} The protein target is bifunctional purine biosynthesis protein PURH. $RMSD$ = 7.06\AA\ for Vina, and $RMSD$ = 0.21\AA\ for idock. idock managed to predict a conformation sufficiently close to that of the co-crystallized ligand but AutoDock Vina failed.
}
\label{Redocking1PKX}
\end{figure}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=4in]{Redocking3HV8.eps}
\end{center}
\caption{
{\bf Redocking result of PDB ID 3HV8.} The protein target is FimX. $RMSD$ = 0.29\AA\ for Vina, and $RMSD$ = 10.23\AA\ for idock. AutoDock Vina managed to predict a conformation sufficiently close to that of the co-crystallized ligand but idock failed.
}
\label{Redocking3HV8}
\end{figure}

%\begin{figure}[!ht]
%\begin{center}
%\includegraphics[width=4in]{VinaConf1RMSD-idockConf1RMSD.eps}
%\end{center}
%\caption{
%{\bf $RMSD_1$ of the predicted ligand conformation from the crystal one ($N$ = 201), showing the values for idock and AutoDock Vina. The color encodes the number of rotatable bonds (NRB).} $RMSD_1$ refers to the $RMSD$ value between the crystal conformation and the docked conformation with the highest predicted binding affinity. Very often the $RMSD$ of 2.0\AA\ is regarded as the positive control for correct bound structure prediction.
%}
%\label{VinaConf1RMSD-idockConf1RMSD}
%\end{figure}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=4in]{Program-NRB.eps}
\end{center}
\caption{
{\bf Boxplots of number of rotatable bonds (NRB) of the ligand against the successful and unsuccessful cases of idock and AutoDock Vina ($N$ = 201).} Very often the $RMSD$ of 2.0\AA\ is regarded as the positive control for correct bound structure prediction. Docking a ligand with no greater than 10 rotatable bonds has a higher chance to succeed.
}
\label{Program-NRB}
\end{figure}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=4in]{Program-NIONS.eps}
\end{center}
\caption{
{\bf Boxplots of number of metal ions in the binding site against the successful and unsuccessful cases of idock and AutoDock Vina ($N$ = 201).} Very often the $RMSD$ of 2.0\AA\ is regarded as the positive control for correct bound structure prediction. Docking a ligand with no metal ions in the binding site has a higher chance to succeed.
}
\label{Program-NIONS}
\end{figure}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=4in]{pK-idockConf1idock.eps}
\end{center}
\caption{
{\bf Scatter plot of the lowest idock score of the 9 docked conformations output by idock against the experimental binding affinity on PDBbind v2012 core set ($N$ = 201).} Values are in $pK_d$ or $pK_i$ unit. $R_p$ = 0.502, $R_s$ = 0.530, $RMSE$ = 1.31, $SD$ = 1.32.
}
\label{pK-idockConf1idock}
\end{figure}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=4in]{pK-idockConfsRFScoreMax.eps}
\end{center}
\caption{
{\bf Scatter plot of the highest RF-Score of the 9 docked conformations output by idock against the experimental binding affinity on PDBbind v2012 core set ($N$ = 201).} Values are in $pK_d$ or $pK_i$ unit. $R_p$ = 0.815, $R_s$ = 0.817, $RMSE$ = 0.75, $SD$ = 0.76.
}
\label{pK-idockConfsRFScoreMax}
\end{figure}

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=4in]{pK-idockConf1RFScore.eps}
\end{center}
\caption{
{\bf Scatter plot of the RF-Score of the first docked conformation against the experimental binding affinity on PDBbind v2012 core set ($N$ = 201).} Values are in $pK_d$ or $pK_i$ unit. $R_p$ = 0.855, $R_s$ = 0.859, $RMSE$ = 0.73, $SD$ = 0.73.
}
\label{pK-idockConf1RFScore}
\end{figure}

\section*{Tables}

\begin{table}[!ht]
\caption{
\bf{Comparison of 21 scoring functions on PDBbind v2007 core set ($N$ = 195)}}
\begin{tabular}{lrrr}
\hline
Scoring function & $R_p$ & $R_s$ & $SD$\\
\hline
RF-Score & 0.774 & 0.762 & 1.59\\
ID-Score & 0.753 & 0.779 & 1.63\\
SVR-Score & 0.726 & 0.739 & 1.70\\
X-Score::HMScore & 0.644 & 0.705 & 1.83\\
DrugScoreCSD & 0.569 & 0.627 & 1.96\\
SYBYL::ChemScore & 0.555 & 0.585 & 1.98\\
AutoDock Vina & 0.554 & 0.608 & 1.98\\
idock & 0.546 & 0.612 & 1.99\\
DS::PLP1 & 0.545 & 0.588 & 2.00\\
GOLD::ASP & 0.534 & 0.577 & 2.02\\
SYBYL::G-Score & 0.492 & 0.536 & 2.08\\
DS::LUDI3 & 0.487 & 0.478 & 2.09\\
DS::LigScore2 & 0.464 & 0.507 & 2.12\\
GlideScore-XP & 0.457 & 0.435 & 2.14\\
DS::PMF & 0.445 & 0.448 & 2.14\\
GOLD::ChemScore & 0.441 & 0.452 & 2.15\\
SYBYL::D-Score & 0.392 & 0.447 & 2.19\\
DS::Jain & 0.316 & 0.346 & 2.24\\
GOLD::GoldScore & 0.295 & 0.322 & 2.29\\
SYBYL::PMF-Score & 0.268 & 0.273 & 2.29\\
SYBYL::F-Score & 0.216 & 0.243 & 2.35\\
\end{tabular}
\begin{flushleft}\label{ScoringFunctionComparison} Pearson's correlation coefficient $R_p$, Spearman's correlation coefficient $R_s$ and standard deviation $SD$ of the difference between predicted and experimental binding affinity on PDBbind v2007 core set ($N$ = 195). Scoring functions are sorted in the descending order of $R_p$. RF-Score, AutoDock Vina and idock rank 1st, 7th and 8th respectively in terms of Pearson's correlation coefficient $R_p$. RF-Score, ID-Score, SVR-Score and X-Score are the only scoring functions whose training set do not overlap with the PDBbind v2007 core set. The statistics for AutoDock Vina and idock are reported in this study and the statistics for the other 19 scoring functions are collected from \cite{1313,564,1305,1295}.
\end{flushleft}
\end{table}

\begin{table}[!ht]
\caption{
\bf{Redocking success rates}}
\begin{tabular}{lrrrrrr}
\hline
& \multicolumn{2}{c}{PDBbind v2012} & \multicolumn{2}{c}{PDBbind v2011} & \multicolumn{2}{c}{CSAR NRC HiQ}\\
Condition & idock & Vina & idock & Vina & idock & Vina\\
\hline
$RMSD_1$ = $RMSD_{min}$ & 49\% & 53\% & 47\% & 54\% & 57\% & 71\%\\
$RMSD_2$ = $RMSD_{min}$ & 15\% & 16\% & 16\% & 14\% & 17\% & 13\%\\
$RMSD_3$ = $RMSD_{min}$ &  8\% &  7\% &  8\% &  8\% &  7\% &  4\%\\
$RMSD_4$ = $RMSD_{min}$ &  6\% &  6\% &  6\% &  5\% &  5\% &  3\%\\
$RMSD_5$ = $RMSD_{min}$ &  5\% &  4\% &  5\% &  5\% &  4\% &  1\%\\
$RMSD_6$ = $RMSD_{min}$ &  5\% &  3\% &  5\% &  4\% &  3\% &  3\%\\
$RMSD_7$ = $RMSD_{min}$ &  4\% &  4\% &  5\% &  4\% &  1\% &  2\%\\
$RMSD_8$ = $RMSD_{min}$ &  5\% &  3\% &  4\% &  3\% &  3\% &  2\%\\
$RMSD_9$ = $RMSD_{min}$ &  4\% &  3\% &  4\% &  3\% &  3\% &  2\%\\
\noalign{\smallskip}
$RMSD_1$ \textless\ 0.5 \AA & 10\% & 12\% & 11\% & 12\% & 21\% & 21\%\\
$RMSD_1$ \textless\ 1.0 \AA & 26\% & 31\% & 29\% & 31\% & 40\% & 47\%\\
$RMSD_1$ \textless\ 1.5 \AA & 43\% & 47\% & 45\% & 47\% & 61\% & 67\%\\
$RMSD_1$ \textless\ 2.0 \AA & 51\% & 56\% & 53\% & 56\% & 68\% & 73\%\\
$RMSD_1$ \textless\ 2.5 \AA & 56\% & 61\% & 58\% & 61\% & 72\% & 76\%\\
\noalign{\smallskip}
$RMSD_{min}$ \textless\ 0.5 \AA & 12\% & 15\% & 14\% & 15\% & 24\% & 26\%\\
$RMSD_{min}$ \textless\ 1.0 \AA & 35\% & 40\% & 39\% & 40\% & 54\% & 55\%\\
$RMSD_{min}$ \textless\ 1.5 \AA & 61\% & 65\% & 64\% & 65\% & 78\% & 84\%\\
$RMSD_{min}$ \textless\ 2.0 \AA & 72\% & 79\% & 74\% & 78\% & 86\% & 92\%\\
$RMSD_{min}$ \textless\ 2.5 \AA & 77\% & 85\% & 79\% & 84\% & 90\% & 94\%\\
\end{tabular}
\begin{flushleft}\label{SuccessRate} Redocking success rates of idock and AutoDock Vina on the PDBbind v2012 refined set ($N$ = 2,897), the PDBbind v2011 refined set ($N$ = 2,455), and the CSAR NRC HiQ Set 24Sept2010 ($N$ = 343) under various conditions regarding the $RMSD$ (Root Mean Square Deviation) values between the crystal and docked conformations. By default, both programs output 9 predicted conformations per ligand. $RMSD_i (i = 1,2,...,9)$ refers to the $RMSD$ value between the crystal conformation and the $i$th docked conformation, i.e. the one with the $i$th highest predicted binding affinity, while $RMSD_{min}$ refers to the $RMSD$ value between the crystal conformation and the closest docked conformation, i.e. the one with the minimum $RMSD$ value. $RMSD_{min} = \displaystyle\min_{i}RMSD_i\ (i = 1,2,...,9)$. In conclusion, idock has a slightly higher conformation generation error than AutoDock Vina.
\end{flushleft}
\end{table}

\begin{table}[!ht]
\caption{
\bf{Docking execution time}}
\begin{tabular}{lrrrrrr}
\hline
& \multicolumn{2}{c}{200-300g/mol} & \multicolumn{2}{c}{300-400g/mol} & \multicolumn{2}{c}{400-500g/mol}\\
& CPU & Elapsed & CPU & Elapsed & CPU & Elapsed\\
\hline
\multicolumn{7}{l}{\textbf{1HCL} human cyclin-dependent kinase 2}\\
Vina  & 12.57 &  3.33 & 22.55 &  5.91 & 51.62 & 13.41\\
idock &  0.63 &  0.16 &  0.92 &  0.24 &  1.38 &  0.36\\
\multicolumn{7}{l}{\textbf{1J1B} human tau protein kinase I}\\
Vina  &  9.07 &  2.47 & 14.69 &  3.92 & 32.28 &  8.49\\
idock &  0.78 &  0.21 &  1.25 &  0.33 &  2.35 &  0.62\\
\multicolumn{7}{l}{\textbf{1LI4} human S-adenosylhomocysteine hydrolase}\\
Vina  & 11.82 &  3.30 & 19.08 &  5.22 & 39.41 & 10.64\\
idock &  0.89 &  0.23 &  1.55 &  0.40 &  3.15 &  0.82\\
\multicolumn{7}{l}{\textbf{1V9U} human rhinovirus 2 coat protein VP1}\\
Vina  &  9.80 &  2.95 & 15.55 &  4.62 & 29.75 &  8.49\\
idock &  0.97 &  0.25 &  1.64 &  0.42 &  3.42 &  0.89\\
\multicolumn{7}{l}{\textbf{2IQH} influenza A virus nucleoprotein NP}\\
Vina  &  9.51 &  2.66 & 15.03 &  4.08 & 29.64 &  7.83\\
idock &  0.92 &  0.24 &  1.59 &  0.41 &  3.41 &  0.88\\
\multicolumn{7}{l}{\textbf{2XSK} Escherichia coli curli protein CsgC - SeCys}\\
Vina  & 10.44 &  2.71 & 17.89 &  4.61 & 40.58 & 10.41\\
idock &  0.71 &  0.19 &  1.16 &  0.30 &  2.16 &  0.56\\
\multicolumn{7}{l}{\textbf{2ZD1} HIV-1 reverse transcriptase}\\
Vina  &  9.78 &  2.70 & 17.67 &  4.76 & 42.03 & 11.33\\
idock &  0.97 &  0.25 &  1.52 &  0.39 &  2.60 &  0.69\\
\multicolumn{7}{l}{\textbf{2ZNL} influenza virus RNA polymerase subunit PA}\\
Vina  &  9.49 &  2.60 & 15.04 &  4.01 & 29.97 &  7.82\\
idock &  0.89 &  0.23 &  1.56 &  0.40 &  3.41 &  0.87\\
\multicolumn{7}{l}{\textbf{3BGS} human purine nucleoside phosphorylase}\\
Vina  &  9.59 &  2.57 & 16.50 &  4.37 & 38.42 & 10.14\\
idock &  0.95 &  0.25 &  1.55 &  0.40 &  2.81 &  0.74\\
\multicolumn{7}{l}{\textbf{3H0W} human S-adenosylmethionine decarboxylase}\\
Vina  &  9.85 &  2.64 & 17.67 &  4.70 & 41.69 & 11.04\\
idock &  0.88 &  0.23 &  1.35 &  0.35 &  2.20 &  0.58\\
\multicolumn{7}{l}{\textbf{3IAR} human adenosine deaminase}\\
Vina  & 11.25 &  3.03 & 20.21 &  5.39 & 46.93 & 12.53\\
idock &  0.80 &  0.21 &  1.21 &  0.32 &  2.01 &  0.53\\
\multicolumn{7}{l}{\textbf{3KFN} HIV protease}\\
Vina  & 10.53 &  2.80 & 18.37 &  4.83 & 42.43 & 11.03\\
idock &  0.77 &  0.20 &  1.20 &  0.32 &  2.09 &  0.55\\
\multicolumn{7}{l}{\textbf{Average across the above 12 receptors}}\\
Vina  & 10.31 &  2.81 & 17.52 &  4.70 & 38.73 & 10.26\\
idock &  0.85 &  0.22 &  1.38 &  0.36 &  2.58 &  0.67\\
\end{tabular}
\begin{flushleft}\label{ExecutionTime} CPU time and elapsed time in hours of docking 3,000 clean ligands of 3 molecular weight sets against 12 diverse receptors by AutoDock Vina and idock. idock outperforms AutoDock Vina by at least 8.69 times and at most 37.51 times.
\end{flushleft}
\end{table}

\end{document}
